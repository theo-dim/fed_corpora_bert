{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-319fa80e0a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import datetime as dt\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved state and predict new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = 3,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_statement_fold_1.bin', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "def bert_encoder(text, max_len=512):\n",
    "    \"\"\" Return embedded text vector as a list in max_len with a mask list\"\"\"\n",
    "    text_token = tokenizer.tokenize(text)\n",
    "    text_token = text_token[:max_len-2]\n",
    "    text_token = [\"[CLS]\"] + text_token + [\"[SEP]\"]\n",
    "    text_ids = tokenizer.convert_tokens_to_ids(text_token)\n",
    "    text_ids += [0] * (max_len - len(text_token))\n",
    "    pad_masks = [1] * len(text_token) + [0] * (max_len - len(text_token))\n",
    "    segment_ids = [0] * len(text_token) + [0] * (max_len - len(text_token))\n",
    "    \n",
    "    return text_ids, pad_masks, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../data/FOMC/train_all_df.pickle\", \"rb\")\n",
    "df = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'morning',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'pleased',\n",
       " 'to',\n",
       " 'be',\n",
       " 'here',\n",
       " 'at',\n",
       " 'the',\n",
       " 'urban',\n",
       " 'institute',\n",
       " 'to',\n",
       " 'discuss',\n",
       " 'how',\n",
       " 'to',\n",
       " 'strengthen',\n",
       " 'the',\n",
       " 'community',\n",
       " 'rein',\n",
       " '##ves',\n",
       " '##tment',\n",
       " 'act',\n",
       " '(',\n",
       " 'cr',\n",
       " '##a',\n",
       " ')',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'a',\n",
       " 'key',\n",
       " 'priority',\n",
       " 'for',\n",
       " 'the',\n",
       " 'federal',\n",
       " 'reserve',\n",
       " '.',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'plays',\n",
       " 'a',\n",
       " 'vital',\n",
       " 'role',\n",
       " 'in',\n",
       " 'bringing',\n",
       " 'banks',\n",
       " 'together',\n",
       " 'with',\n",
       " 'community',\n",
       " 'members',\n",
       " ',',\n",
       " 'small',\n",
       " 'businesses',\n",
       " ',',\n",
       " 'local',\n",
       " 'officials',\n",
       " ',',\n",
       " 'and',\n",
       " 'community',\n",
       " 'groups',\n",
       " 'to',\n",
       " 'make',\n",
       " 'investments',\n",
       " 'in',\n",
       " 'their',\n",
       " 'community',\n",
       " \"'\",\n",
       " 's',\n",
       " 'future',\n",
       " '.',\n",
       " '1',\n",
       " 'that',\n",
       " 'is',\n",
       " 'why',\n",
       " 'we',\n",
       " 'are',\n",
       " 'committed',\n",
       " 'to',\n",
       " 'getting',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'reform',\n",
       " 'done',\n",
       " 'right',\n",
       " '.',\n",
       " 'the',\n",
       " 'origins',\n",
       " 'and',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##aan',\n",
       " '##y',\n",
       " 'successful',\n",
       " 'reform',\n",
       " 'must',\n",
       " 'be',\n",
       " 'grounded',\n",
       " 'in',\n",
       " 'the',\n",
       " 'origins',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'and',\n",
       " 'its',\n",
       " 'ongoing',\n",
       " 'importance',\n",
       " 'to',\n",
       " 'low',\n",
       " '-',\n",
       " 'and',\n",
       " 'moderate',\n",
       " '-',\n",
       " 'income',\n",
       " '(',\n",
       " 'l',\n",
       " '##mi',\n",
       " ')',\n",
       " 'neighborhoods',\n",
       " '.',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'several',\n",
       " 'landmark',\n",
       " 'pieces',\n",
       " 'of',\n",
       " 'legislation',\n",
       " 'enacted',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wake',\n",
       " 'of',\n",
       " 'the',\n",
       " 'civil',\n",
       " 'rights',\n",
       " 'movement',\n",
       " 'intended',\n",
       " 'to',\n",
       " 'address',\n",
       " 'in',\n",
       " '##e',\n",
       " '##qui',\n",
       " '##ties',\n",
       " 'in',\n",
       " 'the',\n",
       " 'credit',\n",
       " 'markets',\n",
       " '.',\n",
       " 'by',\n",
       " 'passing',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " ',',\n",
       " 'congress',\n",
       " 'aimed',\n",
       " 'to',\n",
       " 'reverse',\n",
       " 'the',\n",
       " 'di',\n",
       " '##sin',\n",
       " '##ves',\n",
       " '##tment',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'years',\n",
       " 'of',\n",
       " 'government',\n",
       " 'policies',\n",
       " 'and',\n",
       " 'market',\n",
       " 'actions',\n",
       " 'that',\n",
       " 'deprived',\n",
       " 'lower',\n",
       " '-',\n",
       " 'income',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'credit',\n",
       " 'by',\n",
       " 'red',\n",
       " '##lining',\n",
       " '—',\n",
       " 'using',\n",
       " 'red',\n",
       " '-',\n",
       " 'ink',\n",
       " '##ed',\n",
       " 'lines',\n",
       " 'to',\n",
       " 'separate',\n",
       " 'neighborhoods',\n",
       " 'deemed',\n",
       " 'too',\n",
       " 'risky',\n",
       " '.',\n",
       " '2',\n",
       " 'by',\n",
       " 'con',\n",
       " '##fer',\n",
       " '##ring',\n",
       " 'an',\n",
       " 'affirmative',\n",
       " 'and',\n",
       " 'continuing',\n",
       " 'obligation',\n",
       " 'on',\n",
       " 'banks',\n",
       " 'to',\n",
       " 'help',\n",
       " 'meet',\n",
       " 'the',\n",
       " 'credit',\n",
       " 'needs',\n",
       " 'in',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'neighborhoods',\n",
       " 'they',\n",
       " 'serve',\n",
       " ',',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'has',\n",
       " 'not',\n",
       " 'only',\n",
       " 'prompted',\n",
       " 'banks',\n",
       " 'to',\n",
       " 'be',\n",
       " 'more',\n",
       " 'active',\n",
       " 'lend',\n",
       " '##ers',\n",
       " 'in',\n",
       " 'l',\n",
       " '##mi',\n",
       " 'areas',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'important',\n",
       " 'participants',\n",
       " 'in',\n",
       " 'multi',\n",
       " '##se',\n",
       " '##ctor',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'rev',\n",
       " '##ital',\n",
       " '##ize',\n",
       " 'communities',\n",
       " 'across',\n",
       " 'the',\n",
       " 'country',\n",
       " '.',\n",
       " 'pursuant',\n",
       " 'to',\n",
       " 'guidance',\n",
       " 'from',\n",
       " 'the',\n",
       " 'board',\n",
       " 'of',\n",
       " 'governors',\n",
       " ',',\n",
       " 'each',\n",
       " 'of',\n",
       " 'our',\n",
       " 'federal',\n",
       " 'reserve',\n",
       " 'banks',\n",
       " 'houses',\n",
       " 'a',\n",
       " 'group',\n",
       " 'of',\n",
       " 'dedicated',\n",
       " 'community',\n",
       " 'development',\n",
       " 'professionals',\n",
       " 'and',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'examiner',\n",
       " '##s',\n",
       " 'to',\n",
       " 'help',\n",
       " 'banks',\n",
       " 'meet',\n",
       " 'their',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'obligations',\n",
       " '.',\n",
       " 'we',\n",
       " 'are',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'our',\n",
       " 'work',\n",
       " 'in',\n",
       " 'familiar',\n",
       " '##izing',\n",
       " 'banks',\n",
       " 'with',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " \"'\",\n",
       " 's',\n",
       " 'provisions',\n",
       " ',',\n",
       " 'introducing',\n",
       " 'banks',\n",
       " 'to',\n",
       " 'potential',\n",
       " 'partners',\n",
       " 'in',\n",
       " 'their',\n",
       " 'communities',\n",
       " ',',\n",
       " 'and',\n",
       " 'con',\n",
       " '##ven',\n",
       " '##ing',\n",
       " 'conferences',\n",
       " 'to',\n",
       " 'di',\n",
       " '##sse',\n",
       " '##minate',\n",
       " 'research',\n",
       " 'and',\n",
       " 'best',\n",
       " 'practices',\n",
       " '.',\n",
       " '3',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'plays',\n",
       " 'a',\n",
       " 'vital',\n",
       " 'role',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ecosystem',\n",
       " 'supporting',\n",
       " 'economic',\n",
       " 'opportunity',\n",
       " 'in',\n",
       " 'l',\n",
       " '##mi',\n",
       " 'communities',\n",
       " 'in',\n",
       " 'both',\n",
       " 'rural',\n",
       " 'and',\n",
       " 'urban',\n",
       " 'areas',\n",
       " '.',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'direct',\n",
       " 'funds',\n",
       " 'to',\n",
       " 'specific',\n",
       " 'projects',\n",
       " ',',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'encourages',\n",
       " 'banks',\n",
       " 'to',\n",
       " 'engage',\n",
       " 'on',\n",
       " 'the',\n",
       " 'priorities',\n",
       " 'identified',\n",
       " 'by',\n",
       " 'local',\n",
       " 'leaders',\n",
       " 'and',\n",
       " 'more',\n",
       " 'broadly',\n",
       " 'serve',\n",
       " 'credit',\n",
       " 'needs',\n",
       " 'of',\n",
       " 'small',\n",
       " 'businesses',\n",
       " 'and',\n",
       " 'residents',\n",
       " 'of',\n",
       " 'these',\n",
       " 'communities',\n",
       " '.',\n",
       " 'by',\n",
       " 'being',\n",
       " 'inclusive',\n",
       " 'in',\n",
       " 'their',\n",
       " 'lending',\n",
       " 'and',\n",
       " 'investing',\n",
       " ',',\n",
       " 'banks',\n",
       " 'help',\n",
       " 'their',\n",
       " 'local',\n",
       " 'communities',\n",
       " 'to',\n",
       " 'thrive',\n",
       " ',',\n",
       " 'which',\n",
       " 'in',\n",
       " 'turn',\n",
       " 'benefits',\n",
       " 'their',\n",
       " 'core',\n",
       " 'business',\n",
       " '.',\n",
       " 'the',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'this',\n",
       " 'mutually',\n",
       " 'beneficial',\n",
       " 'relationship',\n",
       " 'between',\n",
       " 'banks',\n",
       " 'and',\n",
       " 'their',\n",
       " 'local',\n",
       " 'communities',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'core',\n",
       " 'strengths',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'and',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'our',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'rev',\n",
       " '##ise',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'regulations',\n",
       " 'must',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'local',\n",
       " 'needs',\n",
       " 'and',\n",
       " 'stake',\n",
       " '##holder',\n",
       " 'input',\n",
       " '.',\n",
       " 'what',\n",
       " 'have',\n",
       " 'we',\n",
       " 'learned',\n",
       " 'from',\n",
       " 'stakeholders',\n",
       " '?',\n",
       " 'for',\n",
       " 'several',\n",
       " 'years',\n",
       " ',',\n",
       " 'the',\n",
       " 'federal',\n",
       " 'banking',\n",
       " 'regulators',\n",
       " 'have',\n",
       " 'been',\n",
       " 'asking',\n",
       " 'stakeholders',\n",
       " 'for',\n",
       " 'input',\n",
       " 'on',\n",
       " 'strengthening',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'regulations',\n",
       " 'to',\n",
       " 'help',\n",
       " 'banks',\n",
       " 'better',\n",
       " 'meet',\n",
       " 'the',\n",
       " 'credit',\n",
       " 'needs',\n",
       " 'of',\n",
       " 'the',\n",
       " 'local',\n",
       " 'l',\n",
       " '##mi',\n",
       " 'communities',\n",
       " 'they',\n",
       " 'serve',\n",
       " 'and',\n",
       " 'more',\n",
       " 'closely',\n",
       " 'align',\n",
       " 'with',\n",
       " 'changes',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ways',\n",
       " 'financial',\n",
       " 'products',\n",
       " 'and',\n",
       " 'services',\n",
       " 'are',\n",
       " 'delivered',\n",
       " '.',\n",
       " 'we',\n",
       " 'also',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'calls',\n",
       " 'from',\n",
       " 'banking',\n",
       " 'and',\n",
       " 'community',\n",
       " 'organizations',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'metric',\n",
       " '##s',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'greater',\n",
       " 'up',\n",
       " '##front',\n",
       " 'clarity',\n",
       " 'about',\n",
       " 'evaluation',\n",
       " 'standards',\n",
       " '.',\n",
       " 'we',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'that',\n",
       " 'branches',\n",
       " 'remain',\n",
       " 'as',\n",
       " 'important',\n",
       " 'as',\n",
       " 'ever',\n",
       " 'to',\n",
       " 'their',\n",
       " 'local',\n",
       " 'communities',\n",
       " ',',\n",
       " 'even',\n",
       " 'as',\n",
       " 'the',\n",
       " 'growth',\n",
       " 'of',\n",
       " 'mobile',\n",
       " 'and',\n",
       " 'online',\n",
       " 'services',\n",
       " 'has',\n",
       " 'extended',\n",
       " 'the',\n",
       " 'geographic',\n",
       " 'area',\n",
       " 'that',\n",
       " 'banks',\n",
       " 'are',\n",
       " 'serving',\n",
       " '.',\n",
       " '4',\n",
       " 'the',\n",
       " 'one',\n",
       " 'message',\n",
       " 'we',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'most',\n",
       " 'consistently',\n",
       " 'is',\n",
       " 'that',\n",
       " 'banks',\n",
       " 'and',\n",
       " 'community',\n",
       " 'organizations',\n",
       " 'alike',\n",
       " 'value',\n",
       " 'the',\n",
       " 'activities',\n",
       " 'they',\n",
       " 'undertake',\n",
       " 'under',\n",
       " 'the',\n",
       " 'auspices',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'and',\n",
       " 'have',\n",
       " 'invested',\n",
       " 'considerable',\n",
       " 'time',\n",
       " 'and',\n",
       " 'effort',\n",
       " 'in',\n",
       " 'the',\n",
       " 'associated',\n",
       " 'processes',\n",
       " 'and',\n",
       " 'reporting',\n",
       " '.',\n",
       " '5',\n",
       " 'for',\n",
       " 'that',\n",
       " 'reason',\n",
       " ',',\n",
       " 'stakeholders',\n",
       " 'have',\n",
       " 'asked',\n",
       " 'the',\n",
       " 'regulators',\n",
       " 'to',\n",
       " 'take',\n",
       " 'care',\n",
       " 'as',\n",
       " 'we',\n",
       " 'con',\n",
       " '##tem',\n",
       " '##plate',\n",
       " 'changes',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " '.',\n",
       " '6',\n",
       " 'if',\n",
       " 'the',\n",
       " 'past',\n",
       " 'is',\n",
       " 'any',\n",
       " 'guide',\n",
       " ',',\n",
       " 'major',\n",
       " 'updates',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'regulations',\n",
       " 'happen',\n",
       " 'once',\n",
       " 'every',\n",
       " 'few',\n",
       " 'decades',\n",
       " '.',\n",
       " 'so',\n",
       " 'it',\n",
       " 'is',\n",
       " 'much',\n",
       " 'more',\n",
       " 'important',\n",
       " 'to',\n",
       " 'get',\n",
       " 'reform',\n",
       " 'right',\n",
       " 'than',\n",
       " 'to',\n",
       " 'do',\n",
       " 'it',\n",
       " 'quickly',\n",
       " '.',\n",
       " 'if',\n",
       " 'we',\n",
       " 'only',\n",
       " 'have',\n",
       " 'one',\n",
       " 'opportunity',\n",
       " 'for',\n",
       " 'a',\n",
       " 'few',\n",
       " 'decades',\n",
       " ',',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'reform',\n",
       " 'is',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'best',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'ideas',\n",
       " 'and',\n",
       " 'the',\n",
       " 'broad',\n",
       " '##est',\n",
       " 'input',\n",
       " 'available',\n",
       " '.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'critical',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'carefully',\n",
       " 'the',\n",
       " 'likely',\n",
       " 'effects',\n",
       " 'of',\n",
       " 'any',\n",
       " 'proposed',\n",
       " 'changes',\n",
       " 'on',\n",
       " 'credit',\n",
       " 'access',\n",
       " 'and',\n",
       " 'community',\n",
       " 'development',\n",
       " 'in',\n",
       " 'l',\n",
       " '##mi',\n",
       " 'communities',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'any',\n",
       " 'additional',\n",
       " 'reporting',\n",
       " 'and',\n",
       " 'procedural',\n",
       " 'burden',\n",
       " '##s',\n",
       " 'for',\n",
       " 'banks',\n",
       " '.',\n",
       " 'last',\n",
       " 'year',\n",
       " ',',\n",
       " 'we',\n",
       " 'set',\n",
       " 'out',\n",
       " 'several',\n",
       " 'principles',\n",
       " 'to',\n",
       " 'guide',\n",
       " 'our',\n",
       " 'work',\n",
       " 'on',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'reform',\n",
       " '.',\n",
       " '7',\n",
       " 'revisions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'regulations',\n",
       " 'should',\n",
       " 'reflect',\n",
       " 'the',\n",
       " 'credit',\n",
       " 'needs',\n",
       " 'of',\n",
       " 'local',\n",
       " 'communities',\n",
       " 'and',\n",
       " 'work',\n",
       " 'consistently',\n",
       " 'through',\n",
       " 'the',\n",
       " 'business',\n",
       " 'cycle',\n",
       " '.',\n",
       " 'they',\n",
       " 'should',\n",
       " 'be',\n",
       " 'tailored',\n",
       " 'to',\n",
       " 'banks',\n",
       " 'of',\n",
       " 'different',\n",
       " 'sizes',\n",
       " 'and',\n",
       " 'business',\n",
       " 'strategies',\n",
       " '.',\n",
       " 'they',\n",
       " 'should',\n",
       " 'provide',\n",
       " 'greater',\n",
       " 'clarity',\n",
       " 'in',\n",
       " 'advance',\n",
       " 'about',\n",
       " 'how',\n",
       " 'activities',\n",
       " 'will',\n",
       " 'be',\n",
       " 'evaluated',\n",
       " '.',\n",
       " 'they',\n",
       " 'should',\n",
       " 'encourage',\n",
       " 'banks',\n",
       " 'to',\n",
       " 'seek',\n",
       " 'opportunities',\n",
       " 'in',\n",
       " 'distressed',\n",
       " 'and',\n",
       " 'under',\n",
       " '##ser',\n",
       " '##ved',\n",
       " 'areas',\n",
       " '.',\n",
       " 'and',\n",
       " 'they',\n",
       " 'should',\n",
       " 'recognize',\n",
       " 'that',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'several',\n",
       " 'related',\n",
       " 'laws',\n",
       " 'to',\n",
       " 'promote',\n",
       " 'an',\n",
       " 'inclusive',\n",
       " 'financial',\n",
       " 'sector',\n",
       " '.',\n",
       " 'ground',\n",
       " '##ing',\n",
       " 'metric',\n",
       " '##s',\n",
       " 'in',\n",
       " 'analysis',\n",
       " 'based',\n",
       " 'on',\n",
       " 'data',\n",
       " '##guide',\n",
       " '##d',\n",
       " 'by',\n",
       " 'stake',\n",
       " '##holder',\n",
       " 'input',\n",
       " ',',\n",
       " 'we',\n",
       " 'evaluated',\n",
       " 'how',\n",
       " 'to',\n",
       " 'strengthen',\n",
       " 'the',\n",
       " 'regulation',\n",
       " 'by',\n",
       " 'using',\n",
       " 'metric',\n",
       " '##s',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'greater',\n",
       " 'certainty',\n",
       " 'about',\n",
       " 'how',\n",
       " 'activities',\n",
       " 'will',\n",
       " 'be',\n",
       " 'evaluated',\n",
       " ',',\n",
       " 'while',\n",
       " 'remaining',\n",
       " 'faithful',\n",
       " 'to',\n",
       " 'the',\n",
       " 'core',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'to',\n",
       " 'make',\n",
       " 'credit',\n",
       " 'and',\n",
       " 'retail',\n",
       " 'banking',\n",
       " 'services',\n",
       " 'available',\n",
       " 'in',\n",
       " 'local',\n",
       " 'l',\n",
       " '##mi',\n",
       " 'communities',\n",
       " '.',\n",
       " 'proposed',\n",
       " 'changes',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'regulation',\n",
       " 'must',\n",
       " 'be',\n",
       " 'grounded',\n",
       " 'in',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'data',\n",
       " 'to',\n",
       " 'avoid',\n",
       " 'un',\n",
       " '##int',\n",
       " '##ended',\n",
       " 'consequences',\n",
       " '.',\n",
       " 'because',\n",
       " 'consistent',\n",
       " 'data',\n",
       " 'on',\n",
       " 'cr',\n",
       " '##a',\n",
       " '-',\n",
       " 'eligible',\n",
       " 'activity',\n",
       " 'were',\n",
       " 'not',\n",
       " 'readily',\n",
       " 'available',\n",
       " ',',\n",
       " 'our',\n",
       " 'research',\n",
       " 'staff',\n",
       " 'set',\n",
       " 'about',\n",
       " 'creating',\n",
       " 'a',\n",
       " 'database',\n",
       " 'based',\n",
       " 'on',\n",
       " 'over',\n",
       " '6',\n",
       " ',',\n",
       " '000',\n",
       " 'written',\n",
       " 'public',\n",
       " 'cr',\n",
       " '##a',\n",
       " 'evaluation',\n",
       " '##s',\n",
       " 'from',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'of',\n",
       " 'some',\n",
       " '3',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = df.loc[df['type']=='speech']['text'].iloc[-1]\n",
    "tokenizer.tokenize(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12596154, 0.06326203, 0.8107765 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids, masks, segment_ids = bert_encoder(test_text)\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "output = model(input_ids)[0].detach()\n",
    "F.softmax(output, dim=1).numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame with Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rate</th>\n",
       "      <th>speaker</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>target_lower</th>\n",
       "      <th>target_hold</th>\n",
       "      <th>target_raise</th>\n",
       "      <th>word_count</th>\n",
       "      <th>pred_target</th>\n",
       "      <th>pred_target_lower</th>\n",
       "      <th>pred_target_hold</th>\n",
       "      <th>pred_target_raise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>0</td>\n",
       "      <td>stands ready to adjust the details of these pl...</td>\n",
       "      <td>statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086087</td>\n",
       "      <td>0.871317</td>\n",
       "      <td>0.042596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>0</td>\n",
       "      <td>that could adversely affect policy implementat...</td>\n",
       "      <td>statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454112</td>\n",
       "      <td>0.283197</td>\n",
       "      <td>0.262690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>0</td>\n",
       "      <td>Information received since the Federal Open Ma...</td>\n",
       "      <td>statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032904</td>\n",
       "      <td>0.802003</td>\n",
       "      <td>0.165094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>0</td>\n",
       "      <td>to 2-1/4 percent. This action supports the Com...</td>\n",
       "      <td>statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "      <td>0.190930</td>\n",
       "      <td>0.132232</td>\n",
       "      <td>0.676837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>1</td>\n",
       "      <td>Information received since the Federal Open Ma...</td>\n",
       "      <td>statement</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.787344</td>\n",
       "      <td>0.179365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>1</td>\n",
       "      <td>action supports the Committee's view that sust...</td>\n",
       "      <td>statement</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029169</td>\n",
       "      <td>0.920777</td>\n",
       "      <td>0.050054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>0</td>\n",
       "      <td>Information received since the Federal Open Ma...</td>\n",
       "      <td>statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677126</td>\n",
       "      <td>0.118452</td>\n",
       "      <td>0.204422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>0</td>\n",
       "      <td>action supports the Committee's view that sust...</td>\n",
       "      <td>statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052474</td>\n",
       "      <td>0.826548</td>\n",
       "      <td>0.120978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>1</td>\n",
       "      <td>Information received since the Federal Open Ma...</td>\n",
       "      <td>statement</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045389</td>\n",
       "      <td>0.890039</td>\n",
       "      <td>0.064572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Jerome Powell</td>\n",
       "      <td>1</td>\n",
       "      <td>Information received since the Federal Open Ma...</td>\n",
       "      <td>statement</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018971</td>\n",
       "      <td>0.919591</td>\n",
       "      <td>0.061438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  rate        speaker  target  \\\n",
       "717 2019-07-31  2.00  Jerome Powell       0   \n",
       "718 2019-07-31  2.00  Jerome Powell       0   \n",
       "719 2019-09-18  1.75  Jerome Powell       0   \n",
       "720 2019-09-18  1.75  Jerome Powell       0   \n",
       "721 2019-10-11  1.75  Jerome Powell       1   \n",
       "722 2019-10-11  1.75  Jerome Powell       1   \n",
       "723 2019-10-30  1.50  Jerome Powell       0   \n",
       "724 2019-10-30  1.50  Jerome Powell       0   \n",
       "725 2019-12-11  1.50  Jerome Powell       1   \n",
       "726 2020-01-29  1.50  Jerome Powell       1   \n",
       "\n",
       "                                                  text       type  \\\n",
       "717  stands ready to adjust the details of these pl...  statement   \n",
       "718  that could adversely affect policy implementat...  statement   \n",
       "719  Information received since the Federal Open Ma...  statement   \n",
       "720  to 2-1/4 percent. This action supports the Com...  statement   \n",
       "721  Information received since the Federal Open Ma...  statement   \n",
       "722  action supports the Committee's view that sust...  statement   \n",
       "723  Information received since the Federal Open Ma...  statement   \n",
       "724  action supports the Committee's view that sust...  statement   \n",
       "725  Information received since the Federal Open Ma...  statement   \n",
       "726  Information received since the Federal Open Ma...  statement   \n",
       "\n",
       "     target_lower  target_hold  target_raise word_count  pred_target  \\\n",
       "717             1            0             0        197            1   \n",
       "718             1            0             0        188            0   \n",
       "719             1            0             0        200            1   \n",
       "720             1            0             0        198            2   \n",
       "721             0            1             0        200            1   \n",
       "722             0            1             0        193            1   \n",
       "723             1            0             0        200            0   \n",
       "724             1            0             0        199            1   \n",
       "725             0            1             0        201            1   \n",
       "726             0            1             0        200            1   \n",
       "\n",
       "     pred_target_lower  pred_target_hold  pred_target_raise  \n",
       "717           0.086087          0.871317           0.042596  \n",
       "718           0.454112          0.283197           0.262690  \n",
       "719           0.032904          0.802003           0.165094  \n",
       "720           0.190930          0.132232           0.676837  \n",
       "721           0.033292          0.787344           0.179365  \n",
       "722           0.029169          0.920777           0.050054  \n",
       "723           0.677126          0.118452           0.204422  \n",
       "724           0.052474          0.826548           0.120978  \n",
       "725           0.045389          0.890039           0.064572  \n",
       "726           0.018971          0.919591           0.061438  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"trained_df.pickle\", 'rb')\n",
    "trained_df = pickle.load(file)\n",
    "\n",
    "trained_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trained_df['target']==trained_df['pred_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885832187070152"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trained_df['target']==trained_df['pred_target']) / len(trained_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3-5.3.1)",
   "language": "python",
   "name": "conda_anaconda3-5.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
